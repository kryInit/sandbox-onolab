{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Implementation of time blocking for compression/serialization and de-serialization/de-compression of wavefields with Devito operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "The goal of this tutorial is to prototype the compression/serialization and de-serialization/de-compression for wavefields in Devito. The motivation is using seismic modeling operators for full waveform inversion (FWI). Some of the steps in FWI require the use of previously computed wavefields, and of particular interest the adjoint of the Jacobian linearized operator -- an operator that maps data perturbation into velocity perturbation and is used to build FWI gradients -- requires a zero-lag temporal correlation with the wavefield that is computed with the nonlinear source. \n",
    "\n",
    "There are implemented alternatives to serialization/de-serialization like checkpointing, but we investigate the serialization option here. For more information on checkpointing, please see the details for ```pyrevolve```, a python implementation of `optimal checkpointing` for Devito (https://github.com/devitocodes/pyrevolve).\n",
    "\n",
    "We aim to provide a *proof of concept* for compression/serialization and de-serialization/de-compression of the nonlinear wavefield. We will achieve this via _time blocking_: we will run a number of time steps in the generated c kernel, and then return control to Python for compression/serialization (for the nonlinear forward operator), and de-serialization/de-compression (for the linearized Jacobian forward and adjoint operators).\n",
    "\n",
    "In order to illustrate the use case for serialization, we outline the workflow for computing the gradient of the FWI objective function, ignoring a lot of details, as follows:\n",
    "\n",
    "1. Generate the nonlinear forward modeled data at the receivers $d_{mod}$\n",
    "$$ \n",
    "d_{mod} = F m \n",
    "$$\n",
    "\n",
    "1. Compress and serialize the nonlinear source wavefield to disk in *time blocks* during computation of 1. The entire nonlinear wavefield is of size $[nt,nx,nz]$ in 2D, but we deal with a block of $M$ time steps at a time, so the size of the chunk to be compressed and serialized is $[M,nx,nz]$. \n",
    "\n",
    "1. Compute the data residual $\\delta r$ by differencing observed and modeled data at the receivers \n",
    "$$\n",
    "\\delta r = d_{obs} - d_{mod}\n",
    "$$\n",
    "\n",
    "1. Backproject the data residual $\\delta r$ via time reversal with the adjoint linearized Jacobian operator.\n",
    "\n",
    "1. De-serialize and de-compress the nonlinear source wavefield from disk during computation in step 4, synchronizing time step between the nonlinear wavefield computed forward in time, and time reversed adjoint wavefield. We will deal with de-serialization and de-compression of chunks of $M$ time steps of size $[M,nx,nz]$.\n",
    "\n",
    "1. Increment the model perturbation via zero lag correlation of the de-serialized nonlinear source wavefield and the backprojected receiver adjoint wavefield. Note that this computed model perturbation is the  _gradient_ of the FWI objective function.\n",
    "$$\n",
    "\\delta m = \\bigl( \\nabla F\\bigr)^\\top\\ \\delta r\n",
    "$$\n",
    "\n",
    "Please see other notebooks in the `seismic/self=adjoint` directory for more details, in particular the notebooks describing the self-adjoint modeling operators. \n",
    "\n",
    "| Self-adjoint notebook description | name | \n",
    "|:---|:---|\n",
    "| Nonlinear operator | `sa_01_iso_implementation1.ipynb` |\n",
    "| Jacobian linearized operators | `sa_02_iso_implementation2.ipynb` |\n",
    "| Correctness tests | `sa_03_iso_correctness.ipynb` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline \n",
    "1. Definition of symbols\n",
    "1. Description of tests to verify correctness\n",
    "1. Description of time blocking implementation\n",
    "1. Compression note -- use of ```blosc```\n",
    "1. Create small 2D test model\n",
    "1. Implement and test the Nonlinear forward operation\n",
    "  - Save all time steps \n",
    "  - Time blocking plus compression/serialization\n",
    "  - Ensure differences are at machine epsilon \n",
    "1. Implement and test the Jacobian linearized forward operation\n",
    "  - Save all time steps \n",
    "  - Time blocking plus compression/serialization\n",
    "  - Ensure differences are at machine epsilon \n",
    "1. Implement and test the Jacobian linearized adjoint operation\n",
    "  - Save all time steps \n",
    "  - Time blocking plus compression/serialization\n",
    "  - Ensure differences are at machine epsilon \n",
    "1. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of symbols\n",
    "\n",
    "We show the symbols here relevant to the implementation of the linearized operators.\n",
    "\n",
    "| Symbol &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | Description  | Dimensionality | \n",
    "|:---|:---|:---|\n",
    "| $m_0(x,y,z)$ | Reference P wave velocity    | function of space |\n",
    "| $\\delta m(x,y,z)$ | Perturbation to P wave velocity    | function of space |\n",
    "| $u_0(t,x,y,z)$ | Reference pressure wavefield | function of time and space |\n",
    "| $\\delta u(t,x,y,z)$ | Perturbation to pressure wavefield | function of time and space |\n",
    "| $q(t,x,y,z)$ | Source wavefield | function of time, localized in space to source location |\n",
    "| $r(t,x,y,z)$ | Receiver wavefield | function of time, localized in space to receiver locations |\n",
    "| $\\delta r(t,x,y,z)$ | Receiver wavefield perturbation | function of time, localized in space to receiver locations |\n",
    "| $F[m; q]$ | Forward nonlinear modeling operator | Nonlinear in $m$, linear in $q$: $\\quad$ maps $m \\rightarrow r$ |\n",
    "| $\\nabla F[m; q]\\ \\delta m$ | Forward Jacobian modeling operator | Linearized at $[m; q]$: $\\quad$ maps $\\delta m \\rightarrow \\delta r$ |\n",
    "| $\\bigl( \\nabla F[m; q] \\bigr)^\\top\\ \\delta r$ | Adjoint Jacobian modeling operator | Linearized at $[m; q]$: $\\quad$ maps $\\delta r \\rightarrow \\delta m$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of tests to verify correctness\n",
    "\n",
    "In order to make sure we have implemented the time blocking correctly, we numerically compare the output from two runs:\n",
    "1. all time steps saved implementation -- requires a lot of memory to hold wavefields at each time step\n",
    "1. time blocking plus compression/serialization implementation -- requires only enough memory to hold the wavefields in a time block  \n",
    "\n",
    "We perform these tests for three phases of FWI modeling:\n",
    "1. nonlinear forward: maps model to data, *forward in time*\n",
    "1. Jacobian linearized forward: maps model perturbation to data perturbation, *forward in time*\n",
    "1. Jacobian linearized adjoint: maps data perturbation to model perturbation, *backward in time*\n",
    "\n",
    "We will design a small 2D test experiment with a source in the middle of the model and short enough elapsed modeling time that we do not need to worry about boundary reflections for these tests, or runnin out of memory saving all time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of time blocking implementation\n",
    "\n",
    "We gratefully acknowledge Downunder Geosolutions (DUG) for in depth discussions about their production time blocking implementation. Those discussions shaped the implementation shown here. The most important idea is to separate the programmatic containers used for propagation and serialization. To do this we utilize two distinct ```TimeFunction```'s.\n",
    "\n",
    "### Propagation uses ```TimeFunction(..., save=None)```\n",
    "\n",
    "We use a default constructed ```TimeFunction``` for propagation. This can be specified in the constructor via either ```save=None``` or no ```save``` argument at all. Devito backs such a default ```TimeFunction``` by a ```Buffer``` of size ```time_order+1```, or 3 for second order in time. We show below the mapping from the monotonic *ordinary time indices* to the buffered *modulo time indices* as used by a ```Buffer``` in a ```TimeFuntion``` with ```time_order=2```.\n",
    "\n",
    "### Modulo indexing for ```Buffer``` of size 3\n",
    "```\n",
    "Ordinary time indices:  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n",
    "Modulo   time indices:  0  1  2  0  1  2  0  1  2  0  1  2  0  1  2  0\n",
    "```\n",
    "\n",
    "*Important note:* the modulo indexing of ```Buffer``` is the reason we will separate propagation from serialization. If we use a larger ```Bufffer``` as the ```TimeFunction``` for propagation, we would have to deal with the modulo indexing not just for the current time index, but also previous and next time indices (assuming second order in time). This means that the previous and next time steps can overwrite the locations of the ordinary time indices when you propagate for a block of time steps. **This is the reason we do not use the same ```TimeFunction``` for both propagation and serialization.**\n",
    "\n",
    "### Generated code for a second order in time PDE\n",
    "We now show an excerpt from Devito generated code for a second order in time operator. A second order in time PDE requires two wavefields in order to advance in time: the wavefield at the next time step $u(t+\\Delta t)$ is a function of the wavefield at previous time step $u(t-\\Delta t)$ and the wavefield at the current time step $u(t)$. Remember that Devito uses a ```Buffer``` of size 3 to handle this. \n",
    "\n",
    "In the generated code there are three modulo time indices that are a function of ordinary time and cycle through the values $[0,1,2]$:\n",
    "* ```t0``` -- current time step\n",
    "* ```t1``` -- next time step\n",
    "* ```t2``` -- previous time step\n",
    "\n",
    "We show an excerpt at the beginning of the time loop from the generated code below, with ordinary time loop index ```time```. Note that we have simplified the generated code by breaking a single for loop specification line into multiple lines for clarity. We have also added comments to help understand the mapping from ordinary to modulo time indices.\n",
    "\n",
    "```\n",
    "for (int time = time_m; time <= time_M; time += 1) {\n",
    "  t0 = (time + 0)%(3);    // time index for the current time step \n",
    "  t1 = (time + 1)%(3);    // time index for the next time step\n",
    "  t2 = (time + 2)%(3);    // time index for the  previous time step\n",
    "  \n",
    "  // ... PIE: propagation, source injection, receiver extraction ...\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "It should be obvious that using a single container for both propagation and serialization is problematic because the loop runs over ordinary time indices ```time_m``` through ```time_M```, but will access stored previous time step wavefields at indices ```time_m-1``` through ```time_M-1``` and store computed next time step wavefields in indices ```time_m+1``` through ```time_M+1```. \n",
    "\n",
    "### Serialization uses ```TimeFunction(..., save=Buffer(M))``` \n",
    "\n",
    "We will use an independent second ```Buffer``` of size $M$ for serialization in our time blocking implementation. This second ```TimeFunction``` will also use modulo indexing, but by design we only access indices ```time_m``` through ```time_M``` in each time block. This means we do not need to worry about wrapping indices from previous time step or next time step wavefields.\n",
    "\n",
    "### Minimum and maximum allowed time index for second order PDE\n",
    "\n",
    "It is important to note that for a second order in time system the minimum allowed time index ```time_m``` will be $1$, because time index $0$ would imply that the previous time step wavefield $u(t-\\Delta t)$ exists at time index $-1$, and $0$ is the minimum array location.\n",
    "\n",
    "Similarly, the maximum allowed time index ```time_M``` will be $nt-2$, because time index $nt-1$ would imply that the next time step wavefield $u(t+\\Delta t)$ exists at time index $nt$, and $nt-1$ is the maximum array location.\n",
    "\n",
    "### Flow charts for time blocking\n",
    "\n",
    "Putting this all together, here are flow charts outlining control flow the first two time blocks with $M=5$.\n",
    "\n",
    "#### Time blocking for the nonlinear forward\n",
    "\n",
    "```\n",
    "Time block 1\n",
    "    Call generated code Operator(time_m=1, time_M=5)\n",
    "\tReturn control to Python\n",
    "    Compress indices 1,2,3,4,5\n",
    "    Serialize indices 1,2,3,4,5 \n",
    "        (access modulo indices 1%5,2%5,3%5,4%5,5%5)\n",
    "\n",
    "Time block 2\n",
    "    Call generated code Operator(time_m=6, time_M=10)\n",
    "\tReturn control to Python\n",
    "    Compress indices 6,7,8,9,10\n",
    "    Serialize indices 6,7,8,9,10\n",
    "        (access modulo indices 6%5,7%5,8%5,9%5,10%5)\n",
    "```\n",
    "\n",
    "#### Time blocking for the linearized Jacobian adjoint (time reversed)\n",
    "\n",
    "```\n",
    "Time block 2\n",
    "    De-serialize indices 6,7,8,9,10\n",
    "    De-compress indices 6,7,8,9,10\n",
    "        (access modulo indices 6%5,7%5,8%5,9%5,10%5)\n",
    "    Call generated code Operator(time_m=6, time_M=10)\n",
    "\tReturn control to Python\n",
    "\n",
    "Time block 1\n",
    "    De-serialize indices 1,2,3,4,5 \n",
    "    De-compress indices 1,2,3,4,5\n",
    "        (access modulo indices 1%5,2%5,3%5,4%5,5%5)\n",
    "    Call generated code Operator(time_m=1, time_M=5)\n",
    "\tReturn control to Python\n",
    "```\n",
    "\n",
    "## Arrays used to save file offsets and compressed sizes\n",
    "\n",
    "We use two arrays the length of the total number of time steps to save bookeeping information used for the serialization and compression. During de-serialization these offsets and lengths will be used to seek the correct location and read the correct length from the binary file saving the compressed data.\n",
    "\n",
    "| Array | Description |\n",
    "|:---|:---|\n",
    "| file_offset | stores the location of the start of the compressed block for each time step | \n",
    "| file_length | stores the length of the compressed block for each time step | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression note -- use of ```blosc```\n",
    "\n",
    "In this notebook we use ```blosc``` compression that is not loaded by default in devito. The first operational cell immediately below ensures that  ```blosc``` compression and Python wrapper are installed in this jupyter kernel. \n",
    "\n",
    "Note that ```blosc``` provides *lossless compression*, and in practice one would use *lossy compression* to achieve significantly better compression ratios. Consider the use of ```blosc``` here as a placeholder for your compression method of choice, providing all the essential characteristics of what might be used at scale. \n",
    "\n",
    "We will use the low level interface to blosc compression because it allows the easiest use of numpy arrays. A synopsis of the compression and decompression calls is shown below for devito ```TimeFunction``` $u$, employing compression level $9$ of the ```zstd``` type with the optional shuffle, at modulo time index ```kt%M```.\n",
    "\n",
    "```\n",
    "    c = blosc.compress_ptr(u._data[kt%M,:,:].__array_interface__['data'][0], \n",
    "                           np.prod(u2._data[kt%M,:,:].shape), \n",
    "                           u._data[kt%M,:,:].dtype.itemsize, 9, True, 'zstd')\n",
    "    \n",
    "    blosc.decompress_ptr(u._data[kt,:,:], d.__array_interface__['data'][0])\n",
    "```\n",
    "\n",
    "```blosc``` Reference:\n",
    "* c project and library: https://blosc.org\n",
    "* Python wrapper: https://github.com/Blosc/python-blosc\n",
    "* Python wrapper documentation: http://python-blosc.blosc.org\n",
    "* low level interface to compression call: http://python-blosc.blosc.org/tutorial.html#compressing-from-a-data-pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Install pyzfp package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install blosc\n",
    "import blosc"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "\n",
    "We have grouped all imports used in this notebook here for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from examples.seismic import RickerSource, Receiver, TimeAxis\n",
    "from devito import (Grid, Function, TimeFunction, SpaceDimension, Constant, \n",
    "                    Eq, Operator, configuration, norm, Buffer)\n",
    "from examples.seismic.self_adjoint import setup_w_over_q\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# These lines force images to be displayed in the notebook, and scale up fonts \n",
    "%matplotlib inline\n",
    "mpl.rc('font', size=14)\n",
    "\n",
    "# Make white background for plots, not transparent\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Set logging to debug, captures statistics on the performance of operators\n",
    "# configuration['log-level'] = 'DEBUG'\n",
    "configuration['log-level'] = 'INFO'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model for a two dimensional problem\n",
    "We are aiming at a small model as this is a POC.\n",
    " - 101 x 101 cell model \n",
    " - 20x20 m discretization \n",
    " - Modeling sample rate explicitly chosen: 2.5 msec\n",
    " - Time range 250 milliseconds (101 time steps)\n",
    " - Wholespace model\n",
    "   - velocity: 1500 m/s\n",
    "   - density: 1 g/cm^3\n",
    " - Source to left of center \n",
    " - Vertical line of receivers to right of center \n",
    " - Velocity perturbation box for linearized ops in center of model\n",
    " - Visco-acoustic absorbing boundary from the self-adjoint operators linked above, 10 points on exterior boundaries.\n",
    " - We generate a velocity perturbation for the linearized forward Jacobian operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Define dimensions for the interior of the model\n",
    "nx,nz = 101,101\n",
    "npad = 10\n",
    "dx,dz = 20.0,20.0  # Grid spacing in m\n",
    "shape = (nx, nz)   # Number of grid points\n",
    "spacing = (dx, dz) # Domain size is now 5 km by 5 km\n",
    "origin = (0., 0.)  # Origin of coordinate system, specified in m.\n",
    "extent = tuple([s*(n-1) for s, n in zip(spacing, shape)])\n",
    "\n",
    "# Define the dimensions \n",
    "x = SpaceDimension(name='x', spacing=Constant(name='h_x', value=extent[0]/(shape[0]-1)))\n",
    "z = SpaceDimension(name='z', spacing=Constant(name='h_z', value=extent[1]/(shape[1]-1)))\n",
    "\n",
    "# Initialize the Devito grid \n",
    "dtype = np.float32\n",
    "grid = Grid(extent=extent, shape=shape, origin=origin, dimensions=(x, z), dtype=dtype)\n",
    "\n",
    "print(\"shape;           \", shape)\n",
    "print(\"origin;          \", origin)\n",
    "print(\"spacing;         \", spacing)\n",
    "print(\"extent;          \", extent)\n",
    "\n",
    "print(\"\")\n",
    "print(\"grid.shape;      \", grid.shape)\n",
    "print(\"grid.extent;     \", grid.extent)\n",
    "print(\"grid.spacing_map;\", grid.spacing_map)\n",
    "\n",
    "# Create velocity and buoyancy fields. \n",
    "space_order = 8\n",
    "m0 = Function(name='m0', grid=grid, space_order=space_order)\n",
    "b = Function(name='b', grid=grid, space_order=space_order)\n",
    "m0.data[:] = 1.5\n",
    "b.data[:,:] = 1.0 / 1.0\n",
    "\n",
    "# Perturbation to velocity: a square offset from the center of the model\n",
    "dm = Function(name='dm', grid=grid, space_order=space_order)\n",
    "size = 4\n",
    "x0 = (nx-1)//2 + 1\n",
    "z0 = (nz-1)//2 + 1\n",
    "dm.data[:] = 0.0\n",
    "dm.data[(x0-size):(x0+size+1), (z0-size):(z0+size+1)] = 1.0\n",
    "\n",
    "# Initialize the attenuation profile for the absorbing boundary\n",
    "fpeak = 0.001\n",
    "w = 2.0 * np.pi * fpeak\n",
    "qmin = 0.1\n",
    "wOverQ = Function(name='wOverQ_025', grid=grid, space_order=space_order)\n",
    "setup_w_over_q(wOverQ, w, qmin, 100.0, npad)\n",
    "\n",
    "# Time sampling\n",
    "t0 = 0    # Simulation time start\n",
    "tn = 250  # Simulation time end\n",
    "dt = 2.5  # Simulation time step interval\n",
    "time_range = TimeAxis(start=t0, stop=tn, step=dt)\n",
    "nt = time_range.num\n",
    "print(\"\")\n",
    "print(\"time_range; \", time_range)\n",
    "\n",
    "# Source 10 Hz center frequency\n",
    "src = RickerSource(name='src', grid=grid, f0=fpeak, npoint=1, time_range=time_range)\n",
    "src.coordinates.data[0,:] = [dx * ((nx-1) / 2 - 10), dz * (nz-1) / 2]\n",
    "\n",
    "# Receivers: for nonlinear forward and linearized forward\n",
    "# one copy each for save all and time blocking implementations\n",
    "nr = 51\n",
    "z1 = dz * ((nz - 1) / 2 - 40)\n",
    "z2 = dz * ((nz - 1) / 2 + 40)\n",
    "\n",
    "nl_rec1 = Receiver(name='nl_rec1', grid=grid, npoint=nr, time_range=time_range)\n",
    "nl_rec2 = Receiver(name='nl_rec2', grid=grid, npoint=nr, time_range=time_range)\n",
    "ln_rec1 = Receiver(name='ln_rec1', grid=grid, npoint=nr, time_range=time_range)\n",
    "ln_rec2 = Receiver(name='ln_rec2', grid=grid, npoint=nr, time_range=time_range)\n",
    "nl_rec1.coordinates.data[:,0] = nl_rec2.coordinates.data[:,0] = \\\n",
    "    ln_rec1.coordinates.data[:,0] = ln_rec2.coordinates.data[:,0] = dx * ((nx-1) / 2 + 10)\n",
    "nl_rec1.coordinates.data[:,1] = nl_rec2.coordinates.data[:,1] = \\\n",
    "    ln_rec1.coordinates.data[:,1] = ln_rec2.coordinates.data[:,1] = np.linspace(z1, z2, nr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"src_coordinate  X;         %+12.4f\" % (src.coordinates.data[0,0]))\n",
    "print(\"src_coordinate  Z;         %+12.4f\" % (src.coordinates.data[0,1]))\n",
    "print(\"rec_coordinates X min/max; %+12.4f %+12.4f\" % \\\n",
    "      (np.min(nl_rec1.coordinates.data[:,0]), np.max(nl_rec1.coordinates.data[:,0])))\n",
    "print(\"rec_coordinates Z min/max; %+12.4f %+12.4f\" % \\\n",
    "      (np.min(nl_rec1.coordinates.data[:,1]), np.max(nl_rec1.coordinates.data[:,1])))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot velocity and density models\n",
    "\n",
    "Next we plot the velocity and density models for illustration, with source location shown as a large red asterisk and receiver line shown as a black line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "#NBVAL_IGNORE_OUTPUT\n",
    "# note: flip sense of second dimension to make the plot positive downwards\n",
    "plt_extent = [origin[0], origin[0] + extent[0], origin[1] + extent[1], origin[1]]\n",
    "\n",
    "vmin, vmax = 1.4, 1.7\n",
    "pmin, pmax = -1, +1\n",
    "dmin, dmax = 0.9, 1.1\n",
    "\n",
    "plt.figure(figsize=(12,14))\n",
    "\n",
    "# plot velocity \n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.transpose(m0.data), cmap=cm.jet, \n",
    "           vmin=vmin, vmax=vmax, extent=plt_extent)\n",
    "plt.colorbar(orientation='horizontal', label='Velocity (m/msec)')\n",
    "plt.plot(nl_rec1.coordinates.data[:, 0], nl_rec1.coordinates.data[:, 1], \\\n",
    "         'black', linestyle='-', label=\"Receiver\")\n",
    "plt.plot(src.coordinates.data[:, 0], src.coordinates.data[:, 1], \\\n",
    "         'red', linestyle='None', marker='*', markersize=15, label=\"Source\")\n",
    "plt.xlabel(\"X Coordinate (m)\")\n",
    "plt.ylabel(\"Z Coordinate (m)\")\n",
    "plt.title(\"Constant velocity\")\n",
    "\n",
    "# plot density\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.transpose(1 / b.data), cmap=cm.jet,\n",
    "           vmin=dmin, vmax=dmax, extent=plt_extent)\n",
    "plt.colorbar(orientation='horizontal', label='Density (m^3/kg)')\n",
    "plt.plot(nl_rec1.coordinates.data[:, 0], nl_rec1.coordinates.data[:, 1], \\\n",
    "         'black', linestyle='-', label=\"Receiver\")\n",
    "plt.plot(src.coordinates.data[:, 0], src.coordinates.data[:, 1], \\\n",
    "         'red', linestyle='None', marker='*', markersize=15, label=\"Source\")\n",
    "plt.xlabel(\"X Coordinate (m)\")\n",
    "plt.ylabel(\"Z Coordinate (m)\")\n",
    "plt.title(\"Constant density\")\n",
    "\n",
    "# plot velocity perturbation\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.transpose(dm.data), cmap=\"seismic\", \n",
    "           vmin=pmin, vmax=pmax, extent=plt_extent)\n",
    "plt.colorbar(orientation='horizontal', label='Velocity (m/msec)')\n",
    "plt.plot(nl_rec1.coordinates.data[:, 0], nl_rec1.coordinates.data[:, 1], \\\n",
    "         'black', linestyle='-', label=\"Receiver\")\n",
    "plt.plot(src.coordinates.data[:, 0], src.coordinates.data[:, 1], \\\n",
    "         'red', linestyle='None', marker='*', markersize=15, label=\"Source\")\n",
    "plt.xlabel(\"X Coordinate (m)\")\n",
    "plt.ylabel(\"Z Coordinate (m)\")\n",
    "plt.title(\"Velocity Perturbation\")\n",
    "\n",
    "# Plot the log of the generated Q profile\n",
    "q = np.log10(w / wOverQ.data)\n",
    "lmin, lmax = np.log10(qmin), np.log10(100)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.transpose(q.data), cmap=cm.jet, vmin=lmin, vmax=lmax, extent=plt_extent)\n",
    "plt.colorbar(orientation='horizontal', label='log10(Q)')\n",
    "plt.plot(nl_rec1.coordinates.data[:, 0], nl_rec1.coordinates.data[:, 1], \\\n",
    "         'black', linestyle='-', label=\"Receiver\")\n",
    "plt.plot(src.coordinates.data[:, 0], src.coordinates.data[:, 1], \\\n",
    "         'red', linestyle='None', marker='*', markersize=15, label=\"Source\")\n",
    "plt.xlabel(\"X Coordinate (m)\")\n",
    "plt.ylabel(\"Z Coordinate (m)\")\n",
    "plt.title(\"log10 of $Q$ model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "None"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the nonlinear forward\n",
    "\n",
    "We copy the nonlinear forward PDE described in the 1st self-adjoint notebook linked above:\n",
    "\n",
    "$$\n",
    "L_t[\\cdot] \\equiv \\frac{\\omega_c}{Q} \\overleftarrow{\\partial_t}[\\cdot] + \\partial_{tt}[\\cdot]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{b}{m^2} L_t[u] =\n",
    "    \\overleftarrow{\\partial_x}\\left(b\\ \\overrightarrow{\\partial_x}\\ u \\right) +\n",
    "    \\overleftarrow{\\partial_y}\\left(b\\ \\overrightarrow{\\partial_y}\\ u \\right) +\n",
    "    \\overleftarrow{\\partial_z}\\left(b\\ \\overrightarrow{\\partial_z}\\ u \\right) + q\n",
    "$$\n",
    "\n",
    "## Quantity that is serialized \n",
    "\n",
    "Recall that for Jacobian operators we need the scaled time derivatives of the reference wavefield for both the Born source in the Jacobian forward, and the imaging condition in the Jacobian adjoint. The quantity shown below is used in those expressions, and this is what we will serialize and compress during the nonlinear forward.\n",
    "\n",
    "$$\n",
    "\\frac{2\\ b}{m_0}\\ L_t[u_0] \n",
    "$$\n",
    "\n",
    "## The two implementations\n",
    "\n",
    "We borrow the stencil from the self-adjoint operators shown in the jupyter notebooks linked above, and make two operators. Here are details about the configuration.\n",
    "\n",
    "### Save all time steps implementation\n",
    "  * wavefield for propagation: ```u1 = TimeFunctions(..., save=None)```\n",
    "  * wavefield for serialization: ```v1 = TimeFunctions(..., save=nt)```\n",
    "  * Run the operator in a single execution from ```time_m=1``` to ```time_M=nt-1```\n",
    "\n",
    "### Time blocking implementation\n",
    "  * wavefield for propagation: ```u2 = TimeFunctions(..., save=None)```\n",
    "  * wavefield for serialization: ```v2 = TimeFunctions(..., save=Buffer(M))```\n",
    "  * Run the operator in a sequence of time blocks, each with $M$ time steps, from ```time_m=1``` to ```time_M=nt-1```\n",
    "  \n",
    "## Note on code duplication\n",
    "\n",
    "The stencils for the two operators you see below are exactly the same, the only significant difference is that we use two different ```TimeFunction```s. We could therefore reduce code duplication in two ways:\n",
    "\n",
    "1. Use the placeholder design pattern and ```stencil.subs``` to substitude the appropriate ```TimeFunction```. \n",
    "Please see the FAQ for more information [https://github.com/devitocodes/devito/wiki/FAQ#how-are-abstractions-used-in-the-seismic-examples](https://github.com/devitocodes/devito/wiki/FAQ#how-are-abstractions-used-in-the-seismic-examples)\n",
    "\n",
    "2. Write a function and use it to build the stencils.\n",
    "\n",
    "To increase the clarity of the exposition below, We do neither of these and duplicate the stencil code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Define M: number of time steps in each time block\n",
    "M = 5\n",
    "\n",
    "# Create TimeFunctions\n",
    "u1 = TimeFunction(name=\"u1\", grid=grid, time_order=2, space_order=space_order, save=None)\n",
    "u2 = TimeFunction(name=\"u2\", grid=grid, time_order=2, space_order=space_order, save=None)\n",
    "v1 = TimeFunction(name=\"v1\", grid=grid, time_order=2, space_order=space_order, save=nt)\n",
    "v2 = TimeFunction(name=\"v2\", grid=grid, time_order=2, space_order=space_order, save=Buffer(M))\n",
    "\n",
    "# get time and space dimensions \n",
    "t,x,z = u1.dimensions\n",
    "\n",
    "# Source terms (see notebooks linked above for more detail)\n",
    "src1_term = src.inject(field=u1.forward, expr=src * t.spacing**2 * m0**2 / b)\n",
    "src2_term = src.inject(field=u2.forward, expr=src * t.spacing**2 * m0**2 / b)\n",
    "nl_rec1_term = nl_rec1.interpolate(expr=u1.forward)\n",
    "nl_rec2_term = nl_rec2.interpolate(expr=u2.forward)\n",
    "\n",
    "# The nonlinear forward time update equation\n",
    "update1 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * u1.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) + \\\n",
    "     (b * u1.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2)) + \\\n",
    "    (2 - t.spacing * wOverQ) * u1 + \\\n",
    "    (t.spacing * wOverQ - 1) * u1.backward\n",
    "\n",
    "update2 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * u2.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) + \\\n",
    "     (b * u2.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2)) + \\\n",
    "    (2 - t.spacing * wOverQ) * u2 + \\\n",
    "    (t.spacing * wOverQ - 1) * u2.backward\n",
    "\n",
    "stencil1 = Eq(u1.forward, update1)\n",
    "stencil2 = Eq(u2.forward, update2)\n",
    "\n",
    "# Equations for the Born term\n",
    "v1_term = Eq(v1, (2 * b * m0**-3) * (wOverQ * u1.dt(x0=t-t.spacing/2) + u1.dt2))\n",
    "v2_term = Eq(v2, (2 * b * m0**-3) * (wOverQ * u2.dt(x0=t-t.spacing/2) + u2.dt2))\n",
    "\n",
    "# Update spacing_map (see notebooks linked above for more detail)\n",
    "spacing_map = grid.spacing_map\n",
    "spacing_map.update({t.spacing : dt})\n",
    "\n",
    "# Build the Operators\n",
    "nl_op1 = Operator([stencil1, src1_term, nl_rec1_term, v1_term], subs=spacing_map)\n",
    "nl_op2 = Operator([stencil2, src2_term, nl_rec2_term, v2_term], subs=spacing_map)\n",
    "\n",
    "# Run operator 1 for all time samples\n",
    "u1.data[:] = 0\n",
    "v1.data[:] = 0\n",
    "nl_rec1.data[:] = 0\n",
    "nl_op1(time_m=1, time_M=nt-2)\n",
    "\n",
    "None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the save all timesteps implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "print(\"%.3e\" % norm(u1))\n",
    "print(\"%.3e\" % norm(nl_rec1))\n",
    "print(\"%.3e\" % norm(v1))\n",
    "assert np.isclose(norm(u1), 4.145e+01, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(nl_rec1), 2.669e-03, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(v1), 1.381e-02, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the time blocking implementation over blocks of M time steps\n",
    "\n",
    "After each block of $M$ time steps, we return control to Python to extract the Born term and serialize/compress. \n",
    "\n",
    "The next cell exercises the time blocking operator over $N$ time blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# We make an array the full size for correctness testing\n",
    "v2_all = np.zeros(v1.data.shape, dtype=dtype)\n",
    "\n",
    "# Number of time blocks\n",
    "N = int((nt-1) / M) + 1\n",
    "\n",
    "# Open a binary file in append mode to save the wavefield chunks  \n",
    "filename = \"timeblocking.nonlinear.bin\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "f = open(filename, \"ab\")\n",
    "\n",
    "# Arrays to save offset and length of compressed data\n",
    "file_offset = np.zeros(nt, dtype=np.int64)\n",
    "file_length = np.zeros(nt, dtype=np.int64)\n",
    "\n",
    "# The length of the data type, 4 bytes for float32\n",
    "itemsize = v2.data[0,:,:].dtype.itemsize \n",
    "\n",
    "# The length of a an uncompressed wavefield, used to compute compression ratio below\n",
    "len0 = 4.0 * np.prod(v2._data[0,:,:].shape)\n",
    "\n",
    "# Loop over time blocks\n",
    "v2_all[:] = 0\n",
    "u2.data[:] = 0\n",
    "v2.data[:] = 0\n",
    "nl_rec2.data[:] = 0\n",
    "for kN in range(0,N,1):\n",
    "    kt1 = max((kN + 0) * M, 1)\n",
    "    kt2 = min((kN + 1) * M - 1, nt-2)\n",
    "    nl_op2(time_m=kt1, time_M=kt2)\n",
    "\n",
    "    # Copy computed Born term for correctness testing\n",
    "    for kt in range(kt1,kt2+1):\n",
    "\n",
    "        # assign\n",
    "        v2_all[kt,:,:] = v2.data[(kt%M),:,:]\n",
    "    \n",
    "        # compression\n",
    "        c = blosc.compress_ptr(v2._data[(kt%M),:,:].__array_interface__['data'][0], \n",
    "                               np.prod(v2._data[(kt%M),:,:].shape), \n",
    "                               v2._data[(kt%M),:,:].dtype.itemsize, 9, True, 'zstd')\n",
    "\n",
    "        # compression ratio\n",
    "        cratio = len0 / (1.0 * len(c))\n",
    "        \n",
    "        # serialization\n",
    "        file_offset[kt] = f.tell()\n",
    "        f.write(c)\n",
    "        file_length[kt] = len(c)\n",
    "\n",
    "        # Uncomment these lines to see per time step output\n",
    "#         rms_v1 = np.linalg.norm(v1.data[kt,:,:].reshape(-1))\n",
    "#         rms_v2 = np.linalg.norm(v2_all[kt,:,:].reshape(-1))\n",
    "#         rms_12 = np.linalg.norm(v1.data[kt,:,:].reshape(-1) - v2_all[kt,:,:].reshape(-1))\n",
    "#         print(\"kt1,kt2,len,cratio,|u1|,|u2|,|v1-v2|; %3d %3d %3d %10.4f %12.6e %12.6e %12.6e\" % \n",
    "#               (kt1, kt2, kt2 - kt1 + 1, cratio, rms_v1, rms_v2, rms_12), flush=True)\n",
    "        \n",
    "# Close the binary file\n",
    "f.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the time blocking implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "# Note these are exactly the same norm values as the save all timesteps check above\n",
    "print(\"%.3e\" % norm(nl_rec1))\n",
    "print(\"%.3e\" % np.linalg.norm(v2_all))\n",
    "assert np.isclose(norm(nl_rec1), 2.669e-03, atol=0, rtol=1e-3)\n",
    "assert np.isclose(np.linalg.norm(v2_all), 1.381e-02, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness test for nonlinear forward wavefield\n",
    "\n",
    "We now test correctness by measuring the maximum absolute difference between the wavefields computed with the```Buffer``` and save all time steps implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "norm_v1 = np.linalg.norm(v1.data.reshape(-1))\n",
    "norm_v12 = np.linalg.norm(v1.data.reshape(-1) - v2_all.reshape(-1))\n",
    "\n",
    "print(\"Relative norm of difference wavefield; %+.4e\" % (norm_v12 / norm_v1))\n",
    "\n",
    "assert norm_v12 / norm_v1 < 1e-7"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Jacobian linearized forward\n",
    "\n",
    "As before we have two implementations:\n",
    "1. operates on all time steps in a single implementation and consumes the all time steps saved version of the nonlinear forward wavefield\n",
    "1. operates in time blocks, de-serializes and de-compresses $M$ time steps at a time, and consumes the compressed and serialized time blocking version of the nonlinear forward wavefield \n",
    "\n",
    "One difference in the correctness testing for this case is that we will assign the propagated perturbed wavefields to two ```TimeFunction(..., save=nt)``` for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Create TimeFunctions\n",
    "duFwd1 = TimeFunction(name=\"duFwd1\", grid=grid, time_order=2, space_order=space_order, save=nt)\n",
    "duFwd2 = TimeFunction(name=\"duFwd2\", grid=grid, time_order=2, space_order=space_order, save=nt)\n",
    "\n",
    "ln_rec1_term = ln_rec1.interpolate(expr=duFwd1.forward)\n",
    "ln_rec2_term = ln_rec2.interpolate(expr=duFwd2.forward)\n",
    "\n",
    "# The Jacobian linearized forward time update equation\n",
    "update1 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * duFwd1.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) + \\\n",
    "     (b * duFwd1.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2) + \\\n",
    "     (dm * v1)) + (2 - t.spacing * wOverQ) * duFwd1 + \\\n",
    "    (t.spacing * wOverQ - 1) * duFwd1.backward\n",
    "\n",
    "update2 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * duFwd2.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) + \\\n",
    "     (b * duFwd2.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2) + \\\n",
    "     (dm * v2)) + (2 - t.spacing * wOverQ) * duFwd2 + \\\n",
    "    (t.spacing * wOverQ - 1) * duFwd2.backward\n",
    "\n",
    "stencil1 = Eq(duFwd1.forward, update1)\n",
    "stencil2 = Eq(duFwd2.forward, update2)\n",
    "\n",
    "# Build the Operators\n",
    "lf_op1 = Operator([stencil1, ln_rec1_term], subs=spacing_map)\n",
    "lf_op2 = Operator([stencil2, ln_rec2_term], subs=spacing_map)\n",
    "\n",
    "# Run operator 1 for all time samples\n",
    "duFwd1.data[:] = 0\n",
    "ln_rec1.data[:] = 0\n",
    "lf_op1(time_m=1, time_M=nt-2)\n",
    "\n",
    "None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the save all timesteps implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "print(\"%.3e\" % norm(duFwd1))\n",
    "print(\"%.3e\" % norm(ln_rec1))\n",
    "assert np.isclose(norm(duFwd1), 6.438e+00, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(ln_rec1), 2.681e-02, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the time blocking implementation over blocks of M time steps\n",
    "\n",
    "Before each block of $M$ time steps, we de-serialize and de-compress. \n",
    "\n",
    "### TODO\n",
    "* In the linearized op below figure out how to use a pre-allocated array to hold the compressed bytes, instead of returning a new bytearray each time we read. Note this will not be a problem when not using Python, and there surely must be a way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Open the binary file in read only mode\n",
    "f = open(filename, \"rb\")\n",
    "\n",
    "# Temporay nd array for decompression\n",
    "d = copy.copy(v2._data[0,:,:])\n",
    "\n",
    "# Array to hold compression ratio\n",
    "cratio = np.zeros(nt, dtype=dtype)\n",
    "\n",
    "# Loop over time blocks\n",
    "duFwd2.data[:] = 0\n",
    "ln_rec2.data[:] = 0\n",
    "for kN in range(0,N,1):\n",
    "    kt1 = max((kN + 0) * M, 1)\n",
    "    kt2 = min((kN + 1) * M - 1, nt-2)\n",
    "    \n",
    "    # 1. Seek to file_offset[kt] \n",
    "    # 2. Read file_length[kt1] bytes from file\n",
    "    # 3. Decompress wavefield and assign to v2 Buffer\n",
    "    for kt in range(kt1,kt2+1):\n",
    "        f.seek(file_offset[kt], 0)\n",
    "        c = f.read(file_length[kt])\n",
    "        blosc.decompress_ptr(c, v2._data[(kt%M),:,:].__array_interface__['data'][0])\n",
    "        cratio[kt] = len0 / (1.0 * len(c))\n",
    "\n",
    "    # Run the operator for this time block\n",
    "    lf_op2(time_m=kt1, time_M=kt2)\n",
    "    \n",
    "    # Uncomment these lines to see per time step outputs\n",
    "#     for kt in range(kt1,kt2+1):\n",
    "#         rms_du1 = np.linalg.norm(duFwd1.data[kt,:,:].reshape(-1))\n",
    "#         rms_du2 = np.linalg.norm(duFwd2.data[kt,:,:].reshape(-1))\n",
    "#         rms_d12 = np.linalg.norm(duFwd1.data[kt,:,:].reshape(-1) - duFwd2.data[kt,:,:].reshape(-1))\n",
    "#         print(\"kt1,kt2,len,cratio,|du1|,|du2|,|du1-du2|; %3d %3d %3d %10.4f %12.6e %12.6e %12.6e\" % \n",
    "#               (kt1, kt2, kt2 - kt1 + 1, cratio[kt], rms_du1, rms_du2, rms_d12), flush=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the save all timesteps implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "# Note these are exactly the same norm values as the save all timesteps check above\n",
    "print(\"%.3e\" % norm(duFwd2))\n",
    "print(\"%.3e\" % norm(ln_rec2))\n",
    "assert np.isclose(norm(duFwd2), 6.438e+00, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(ln_rec2), 2.681e-02, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness test for Jacobian forward wavefield\n",
    "\n",
    "We now test correctness by measuring the maximum absolute difference between the wavefields computed with the```Buffer``` and save all time steps implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "norm_du1 = np.linalg.norm(duFwd1.data.reshape(-1))\n",
    "norm_du12 = np.linalg.norm(duFwd1.data.reshape(-1) - duFwd2.data.reshape(-1))\n",
    "\n",
    "print(\"Relative norm of difference wavefield; %+.4e\" % (norm_du12 / norm_du1))\n",
    "\n",
    "assert norm_du12 / norm_du1 < 1e-7"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Jacobian linearized adjoint\n",
    "\n",
    "Again we have two implementations:\n",
    "1. operates on all time steps in a single implementation and consumes the all time steps saved version of the nonlinear forward wavefield\n",
    "1. operates in time blocks, de-serializes and de-compresses $M$ time steps at a time, and consumes the compressed and serialized time blocking version of the nonlinear forward wavefield \n",
    "\n",
    "For correctness testing here we will compare the final gradients computed via these two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Create TimeFunctions for adjoint wavefields\n",
    "duAdj1 = TimeFunction(name=\"duAdj1\", grid=grid, time_order=2, space_order=space_order, save=nt)\n",
    "duAdj2 = TimeFunction(name=\"duAdj2\", grid=grid, time_order=2, space_order=space_order, save=nt)\n",
    "\n",
    "# Create Functions to hold the computed gradients\n",
    "dm1 = Function(name='dm1', grid=grid, space_order=space_order)\n",
    "dm2 = Function(name='dm2', grid=grid, space_order=space_order)\n",
    "\n",
    "# The Jacobian linearized adjoint time update equation\n",
    "update1 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * duAdj1.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) +\n",
    "     (b * duAdj1.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2)) +\\\n",
    "    (2 - t.spacing * wOverQ) * duAdj1 + \\\n",
    "    (t.spacing * wOverQ - 1) * duAdj1.forward\n",
    "\n",
    "update2 = (t.spacing**2 * m0**2 / b) * \\\n",
    "    ((b * duAdj2.dx(x0=x+x.spacing/2)).dx(x0=x-x.spacing/2) +\n",
    "     (b * duAdj2.dz(x0=z+z.spacing/2)).dz(x0=z-z.spacing/2)) +\\\n",
    "    (2 - t.spacing * wOverQ) * duAdj2 + \\\n",
    "    (t.spacing * wOverQ - 1) * duAdj2.forward\n",
    "\n",
    "stencil1 = Eq(duAdj1.backward, update1)\n",
    "stencil2 = Eq(duAdj2.backward, update2)\n",
    "\n",
    "# Equations to sum the zero lag correlations\n",
    "dm1_update = Eq(dm1, dm1 + duAdj1 * v1)\n",
    "dm2_update = Eq(dm2, dm2 + duAdj2 * v2)\n",
    "\n",
    "# We will inject the Jacobian linearized forward receiver data, time reversed\n",
    "la_rec1_term = ln_rec1.inject(field=duAdj1.backward, expr=ln_rec1 * t.spacing**2 * m0**2 / b)\n",
    "la_rec2_term = ln_rec2.inject(field=duAdj2.backward, expr=ln_rec2 * t.spacing**2 * m0**2 / b)\n",
    "\n",
    "# Build the Operators\n",
    "la_op1 = Operator([dm1_update, stencil1, la_rec1_term], subs=spacing_map)\n",
    "la_op2 = Operator([dm2_update, stencil2, la_rec2_term], subs=spacing_map)\n",
    "\n",
    "# Run operator 1 for all time samples\n",
    "duAdj1.data[:] = 0\n",
    "dm1.data[:] = 0\n",
    "la_op1(time_m=1, time_M=nt-2)\n",
    "\n",
    "None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the save all timesteps implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "print(\"%.3e\" % norm(duAdj1))\n",
    "print(\"%.3e\" % norm(dm1))\n",
    "assert np.isclose(norm(duAdj1), 4.626e+01, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(dm1), 1.426e-04, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the time blocking implementation over blocks of M time steps\n",
    "\n",
    "Before each block of $M$ time steps, we de-serialize and de-compress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Open the binary file in read only mode\n",
    "f = open(filename, \"rb\")\n",
    "\n",
    "# Temporay nd array for decompression\n",
    "d = copy.copy(v2._data[0,:,:])\n",
    "\n",
    "# Array to hold compression ratio\n",
    "cratio = np.zeros(nt, dtype=dtype)\n",
    "\n",
    "# Loop over time blocks\n",
    "duAdj2.data[:] = 0\n",
    "dm2.data[:] = 0\n",
    "for kN in range(N-1,-1,-1):\n",
    "    kt1 = max((kN + 0) * M, 1)\n",
    "    kt2 = min((kN + 1) * M - 1, nt-2)\n",
    "        \n",
    "    # 1. Seek to file_offset[kt] \n",
    "    # 2. Read file_length[kt1] bytes from file\n",
    "    # 3. Decompress wavefield and assign to v2 Buffer\n",
    "    for kt in range(kt1,kt2+1,+1):\n",
    "        f.seek(file_offset[kt], 0)\n",
    "        c = f.read(file_length[kt])\n",
    "        blosc.decompress_ptr(c, v2._data[(kt%M),:,:].__array_interface__['data'][0])\n",
    "        cratio[kt] = len0 / (1.0 * len(c))\n",
    "\n",
    "    # Run the operator for this time block\n",
    "    la_op2(time_m=kt1, time_M=kt2)\n",
    "    \n",
    "    # Uncomment these lines to see per time step outputs\n",
    "#     for kt in range(kt2,kt1-1,-1):\n",
    "#         rms_du1 = np.linalg.norm(duAdj1.data[kt,:,:].reshape(-1))\n",
    "#         rms_du2 = np.linalg.norm(duAdj2.data[kt,:,:].reshape(-1))\n",
    "#         rms_d12 = np.linalg.norm(duAdj1.data[kt,:,:].reshape(-1) - duAdj2.data[kt,:,:].reshape(-1))\n",
    "#         print(\"kt2,kt1,kt,cratio,|du1|,|du2|,|du1-du2|; %3d %3d %3d %10.4f %12.6e %12.6e %12.6e\" % \n",
    "#               (kt2, kt1, kt, cratio[kt], rms_du1, rms_du2, rms_d12), flush=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Continuous integration hooks for the save all timesteps implementation\n",
    "# We ensure the norm of these computed wavefields is repeatable\n",
    "# Note these are exactly the same norm values as the save all timesteps check above\n",
    "print(\"%.3e\" % norm(duAdj2))\n",
    "print(\"%.3e\" % norm(dm2))\n",
    "assert np.isclose(norm(duAdj2), 4.626e+01, atol=0, rtol=1e-3)\n",
    "assert np.isclose(norm(dm2), 1.426e-04, atol=0, rtol=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness test for Jacobian adjoint wavefield and computed gradient\n",
    "\n",
    "We now test correctness by measuring the maximum absolute difference between the gradients computed with the```Buffer``` and save all time steps implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "norm_du1 = np.linalg.norm(duAdj1.data.reshape(-1))\n",
    "norm_du12 = np.linalg.norm(duAdj1.data.reshape(-1) - duAdj2.data.reshape(-1))\n",
    "\n",
    "norm_dm1 = np.linalg.norm(dm1.data.reshape(-1))\n",
    "norm_dm12 = np.linalg.norm(dm1.data.reshape(-1) - dm2.data.reshape(-1))\n",
    "\n",
    "print(\"Relative norm of difference wavefield,gradient; %+.4e %+.4e\" % \n",
    "      (norm_du12 / norm_du1, norm_dm12 /norm_dm1))\n",
    "\n",
    "assert norm_du12 / norm_du1 < 1e-7\n",
    "assert norm_dm12 / norm_dm1 < 1e-7"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the file used for serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "os.remove(filename)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
